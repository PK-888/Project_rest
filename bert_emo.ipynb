{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch ç‰ˆæœ¬ï¼š 1.12.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # æŒ‡å®šç¹ç°¡ä¸­æ–‡ BERT-BASE é è¨“ç·´æ¨¡å‹\n",
    "\n",
    "# å–å¾—æ­¤é è¨“ç·´æ¨¡å‹æ‰€ä½¿ç”¨çš„ tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "print(\"PyTorch ç‰ˆæœ¬ï¼š\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650 SUPER'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# torch.cuda.device_count()\n",
    "\n",
    "\n",
    "#torch.cuda.current_device()\n",
    "\n",
    "\n",
    "#torch.cuda.device(0)\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>stars</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ç”Ÿæ—¥èšé¤é¸äº†é€™é–“é¤å»³ï¼Œæ•´é«”ç’°å¢ƒå¾ˆä¹¾æ·¨ä¹Ÿä¸æœƒå¤ªå–§é¬§ï¼Œæœå‹™ä¹Ÿå¾ˆå‘¨åˆ°ã€‚ä¸»èœé»äº†é¹¿è²åŠ›èˆ‡é´¨èƒ¸å¥—é¤éƒ½å¾ˆ...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>æ‡‰è©²äº”é¡†æ˜Ÿçš„ï¼Œå¯æƒœæ²™æ‹‰çš„ç›¤å­æœ‰ç¼ºè§’ï¼Œå°‘äº†ä¸€é¡†æ˜Ÿã€‚é£Ÿæä½¿ç”¨é«˜ç´šï¼Œæœå‹™äººå“¡è§£èªªæ¸…æ¥šã€‚æä¾›åŒ…å ´æœå‹™...</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>æ–™ç†å‘³é“ä¸éŒ¯\\næµ·é®®ç…é¤…å¾ˆå¥½åƒï¼æ¨è–¦å¿…é»\\nè‡ªè£½é¦™è…¸ä»½é‡ä¹Ÿè »å¤ çš„ï¼Œå€¼å¾—å»åƒ\\nåªæ˜¯èšŠå­çœŸçš„æ¯”...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>å¥½å¸‚é›†æ˜¯æˆ‘çš„æ„›åº—ï¼Œä¸çŸ¥é“è¦å»å“ªè£åƒé£¯çš„æ™‚å€™ï¼Œä¾†é€™è£¡å°±å°äº†ã€‚åœ°ä¸­æµ·å‰µæ„æ–™ç†å‘³é“èˆ‡å£æ„Ÿéƒ½å¾ˆä¸éŒ¯ï¼Œ...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>è»Šå­è¦åœå¤–é¢æ”¶è²»è™•ï¼Œå€‹äººæ„Ÿè¦ºè±¬æ’æ¯”è¼ƒå¥½åƒè‚‰å¾ˆå«©ï¼Œåƒ¹ä½æœ‰é»è²´æ±è¥¿éƒ½è¦å–®é»å–”</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>ä¾¿å®œcpå€¼å¾ˆé«˜çš„äº«å—ï¼ŒäºŒæ¨“æŒ‘é«˜è¦–é‡æ£’ï¼Œä¸€æ¨“é€šå¸¸å®¢æ»¿</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>åƒ¹æ ¼åˆç†ï¼Œæ°£æ°›å¾ˆå¥½ï¼Œè®“äººæ„Ÿè¦ºå¾ˆæ‚ é–’ã€‚</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>ä¸çŸ¥ç‚ºä½•ï¼Œè·Ÿå…¶ä»–å®¶å–èµ·ä¾†å‘³é“ä¸ä¸€æ¨£â€¦</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>èˆ’é©ï¼Œæœå‹™æ…‹åº¦é‚„èƒ½å†åŠ å¼·å°±æ›´æ˜¯æ»¿åˆ†</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>éå¸¸é©åˆå»åº—è£¡é»æ¯é£²æ–™\\nåƒå€‹ä¸‰æ˜æ²»</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7207 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  stars  length\n",
       "4     ç”Ÿæ—¥èšé¤é¸äº†é€™é–“é¤å»³ï¼Œæ•´é«”ç’°å¢ƒå¾ˆä¹¾æ·¨ä¹Ÿä¸æœƒå¤ªå–§é¬§ï¼Œæœå‹™ä¹Ÿå¾ˆå‘¨åˆ°ã€‚ä¸»èœé»äº†é¹¿è²åŠ›èˆ‡é´¨èƒ¸å¥—é¤éƒ½å¾ˆ...      1      53\n",
       "5     æ‡‰è©²äº”é¡†æ˜Ÿçš„ï¼Œå¯æƒœæ²™æ‹‰çš„ç›¤å­æœ‰ç¼ºè§’ï¼Œå°‘äº†ä¸€é¡†æ˜Ÿã€‚é£Ÿæä½¿ç”¨é«˜ç´šï¼Œæœå‹™äººå“¡è§£èªªæ¸…æ¥šã€‚æä¾›åŒ…å ´æœå‹™...      1      51\n",
       "6     æ–™ç†å‘³é“ä¸éŒ¯\\næµ·é®®ç…é¤…å¾ˆå¥½åƒï¼æ¨è–¦å¿…é»\\nè‡ªè£½é¦™è…¸ä»½é‡ä¹Ÿè »å¤ çš„ï¼Œå€¼å¾—å»åƒ\\nåªæ˜¯èšŠå­çœŸçš„æ¯”...      1      52\n",
       "7     å¥½å¸‚é›†æ˜¯æˆ‘çš„æ„›åº—ï¼Œä¸çŸ¥é“è¦å»å“ªè£åƒé£¯çš„æ™‚å€™ï¼Œä¾†é€™è£¡å°±å°äº†ã€‚åœ°ä¸­æµ·å‰µæ„æ–™ç†å‘³é“èˆ‡å£æ„Ÿéƒ½å¾ˆä¸éŒ¯ï¼Œ...      1      60\n",
       "8                  è»Šå­è¦åœå¤–é¢æ”¶è²»è™•ï¼Œå€‹äººæ„Ÿè¦ºè±¬æ’æ¯”è¼ƒå¥½åƒè‚‰å¾ˆå«©ï¼Œåƒ¹ä½æœ‰é»è²´æ±è¥¿éƒ½è¦å–®é»å–”      1      36\n",
       "...                                                 ...    ...     ...\n",
       "9595                          ä¾¿å®œcpå€¼å¾ˆé«˜çš„äº«å—ï¼ŒäºŒæ¨“æŒ‘é«˜è¦–é‡æ£’ï¼Œä¸€æ¨“é€šå¸¸å®¢æ»¿      1      25\n",
       "9596                                 åƒ¹æ ¼åˆç†ï¼Œæ°£æ°›å¾ˆå¥½ï¼Œè®“äººæ„Ÿè¦ºå¾ˆæ‚ é–’ã€‚      1      18\n",
       "9597                                 ä¸çŸ¥ç‚ºä½•ï¼Œè·Ÿå…¶ä»–å®¶å–èµ·ä¾†å‘³é“ä¸ä¸€æ¨£â€¦      0      18\n",
       "9598                                  èˆ’é©ï¼Œæœå‹™æ…‹åº¦é‚„èƒ½å†åŠ å¼·å°±æ›´æ˜¯æ»¿åˆ†      1      17\n",
       "9599                                 éå¸¸é©åˆå»åº—è£¡é»æ¯é£²æ–™\\nåƒå€‹ä¸‰æ˜æ²»      1      17\n",
       "\n",
       "[7207 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"è©•è«–åˆ†æ•¸.csv\")\n",
    "\n",
    "df = df.dropna()\n",
    "df['length'] = df.comment.str.len()\n",
    "df = df[df.length < 60]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>éå¸¸æ£’çš„ç”¨é¤é«”é©—ï¼Œæœå‹™äººå“¡è¦ªåˆ‡ç”¨å¿ƒï¼Œåˆé¤æ™‚é–“æ²’æœ‰ç¾Šæ’ï¼Œä¹Ÿç‰¹åœ°å¹«æˆ‘å€‘è©¢å•å»šæˆ¿å¹«å¿™æº–å‚™ğŸ˜‹ğŸ˜‹ğŸ˜‹</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>é€™æ˜¯ä¸€é–“æœ‰åˆ¥ä»¥å¾€\\nå…¶ä»–è·¯æ˜“èçš„æ——è‰¦åº—\\nä¿è­‰æ¯å€‹å®¢äººè²·å®Œå’–å•¡éƒ½æœƒå¦‚æ²æ˜¥é¢¨\\néƒ½æœƒæœŸè¨±è‡ªå·±åƒ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>å˜‰ç¾©çŸ¥åè€åº—,æˆ‘å°æ™‚å€™å¶çˆ¾ä¾†åƒ,Frankå€’æ˜¯æ…•åè€Œä¾†.ç«é›è‚‰é£¯é‚„å¥½,æ»·ç­çµ²å¥½åƒ,é‡‘é‡æ’éª¨æ¹¯...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>ä¸é›£åƒä½†æ²’æœ‰åˆ°ä¸€å®šè¦ä¾†åƒï¼Œç”·è€é—†æ„Ÿè¦ºå¥½åƒä¸æ˜¯å¾ˆæƒ³è·Ÿå®¢äººèªªè©±</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>å¾ˆè®šçš„ç¶“å…¸æ³•åœ‹é¤ï¼Œç´°ç·»çš„å“å‘³ï¼Œä¸‹æ¬¡ä¸€å®šè¦ä¾†ã€‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>å°æ™‚å€™åƒåˆ°å¤§çš„å‘³é“ï¼ä¸ç®¡å…¶ä»–äººèªªé‚„æœ‰æ›´å¥½åƒçš„é›è‚‰é£¯ï¼Œä½†é€™å€‹å‘³é“æœ€åœ°é“ã€‚åªæ˜¯ä¸€ç”²å­çš„åº—æœ‰äº›æ­²æœˆ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>æˆ‘åœ¨å˜‰ç¾©é›è‚‰é£¯æ‰¾åˆ°å–œå¥½ä¹‹ å™´æ°´çœŸçš„ä¸è¡Œï¼Œæ•´å€‹ä¾¿ç•¶æˆ‘åªå°è›‹æœ‰å°è±¡ï¼Œå†·æ‰å‘³é“å¥½è†©å•Šå•Šå•Šï½</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371</th>\n",
       "      <td>è¦ä»ä¸ç´®å¯¦æ„Ÿå¸¶æ²™è…¸æœ‰è¦å‘³\\nç±³é£¯åè»Ÿçˆ›æ¥è¿‘æ²’æ¹¯çš„è¦æ³¡é£¯</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>æœå‹™å¾ˆå¥½ï¼Œé¤é»éƒ½æ˜¯å–®é»å¼ï¼Œä¸€äººå¹³å‡èŠ±è²»$800~$900ï¼Œåƒä¸åˆ°ä»€éº¼æ±è¥¿ï¼Œå¾ˆç©ºè™›</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9249</th>\n",
       "      <td>é€™é–“è·¯æ˜“èçš„é£²æ–™ç›¸è¼ƒæ–¼é¤é»å¥½åƒ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5765 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  stars\n",
       "948        éå¸¸æ£’çš„ç”¨é¤é«”é©—ï¼Œæœå‹™äººå“¡è¦ªåˆ‡ç”¨å¿ƒï¼Œåˆé¤æ™‚é–“æ²’æœ‰ç¾Šæ’ï¼Œä¹Ÿç‰¹åœ°å¹«æˆ‘å€‘è©¢å•å»šæˆ¿å¹«å¿™æº–å‚™ğŸ˜‹ğŸ˜‹ğŸ˜‹      1\n",
       "9492  é€™æ˜¯ä¸€é–“æœ‰åˆ¥ä»¥å¾€\\nå…¶ä»–è·¯æ˜“èçš„æ——è‰¦åº—\\nä¿è­‰æ¯å€‹å®¢äººè²·å®Œå’–å•¡éƒ½æœƒå¦‚æ²æ˜¥é¢¨\\néƒ½æœƒæœŸè¨±è‡ªå·±åƒ...      1\n",
       "2019  å˜‰ç¾©çŸ¥åè€åº—,æˆ‘å°æ™‚å€™å¶çˆ¾ä¾†åƒ,Frankå€’æ˜¯æ…•åè€Œä¾†.ç«é›è‚‰é£¯é‚„å¥½,æ»·ç­çµ²å¥½åƒ,é‡‘é‡æ’éª¨æ¹¯...      0\n",
       "6622                      ä¸é›£åƒä½†æ²’æœ‰åˆ°ä¸€å®šè¦ä¾†åƒï¼Œç”·è€é—†æ„Ÿè¦ºå¥½åƒä¸æ˜¯å¾ˆæƒ³è·Ÿå®¢äººèªªè©±      0\n",
       "952                              å¾ˆè®šçš„ç¶“å…¸æ³•åœ‹é¤ï¼Œç´°ç·»çš„å“å‘³ï¼Œä¸‹æ¬¡ä¸€å®šè¦ä¾†ã€‚      1\n",
       "...                                                 ...    ...\n",
       "3126  å°æ™‚å€™åƒåˆ°å¤§çš„å‘³é“ï¼ä¸ç®¡å…¶ä»–äººèªªé‚„æœ‰æ›´å¥½åƒçš„é›è‚‰é£¯ï¼Œä½†é€™å€‹å‘³é“æœ€åœ°é“ã€‚åªæ˜¯ä¸€ç”²å­çš„åº—æœ‰äº›æ­²æœˆ...      1\n",
       "2765         æˆ‘åœ¨å˜‰ç¾©é›è‚‰é£¯æ‰¾åˆ°å–œå¥½ä¹‹ å™´æ°´çœŸçš„ä¸è¡Œï¼Œæ•´å€‹ä¾¿ç•¶æˆ‘åªå°è›‹æœ‰å°è±¡ï¼Œå†·æ‰å‘³é“å¥½è†©å•Šå•Šå•Šï½      0\n",
       "5371                        è¦ä»ä¸ç´®å¯¦æ„Ÿå¸¶æ²™è…¸æœ‰è¦å‘³\\nç±³é£¯åè»Ÿçˆ›æ¥è¿‘æ²’æ¹¯çš„è¦æ³¡é£¯      0\n",
       "874            æœå‹™å¾ˆå¥½ï¼Œé¤é»éƒ½æ˜¯å–®é»å¼ï¼Œä¸€äººå¹³å‡èŠ±è²»$800~$900ï¼Œåƒä¸åˆ°ä»€éº¼æ±è¥¿ï¼Œå¾ˆç©ºè™›      0\n",
       "9249                                    é€™é–“è·¯æ˜“èçš„é£²æ–™ç›¸è¼ƒæ–¼é¤é»å¥½åƒ      1\n",
       "\n",
       "[5765 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['comment']\n",
    "y = df['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=77)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train\n",
    "# idempotence, å°‡è™•ç†çµæœå¦å­˜æˆ tsv ä¾› PyTorch ä½¿ç”¨\n",
    "train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "# df3.category.value_counts() / len(df3)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>æ˜¯è€åº—ã€‚å®ƒçš„æ²¾é†¬ æ˜¯ç”¨è¦æ®¼ã€é ­ç†¬ç…®çš„ æ‰€ä»¥éå¸¸å¥½åƒã€‚é‚„æœ‰è³£å››ç¥æ¹¯&amp;èŠ‹ç¨ã€‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>ç©ºé–“æ˜äº®ä¹¾æ·¨ï¼Œæœå‹™äººå“¡æ…‹åº¦è¦ªåˆ‡ã€‚äºŒæ¨“åº§ä½å€çš„é•·æ¡Œè¨­æœ‰æ’åº§ï¼Œä½¿ç”¨ä¸‰Cå……é›»æ–¹ä¾¿ã€‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>é¤é»å¥½åƒï¼Œæœå‹™å¥½ï¼\\næ¨è–¦è¥¿ç­ç‰™æ²¹è¦ï¼Œé»äº†ä¸æœƒå¾Œæ‚”ã€‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>ç”¨å¿ƒçš„åº—å®¶ï¼Œé¤é»ä¹Ÿå¥½åƒğŸ˜‹\\nå•¤é…’çœŸçš„å¥½å–é‚„æœ‰ä¼Šæ¯”åˆ©è±¬è‚‰è·Ÿè›‹ç³•æ£’æ£’çš„ğŸ‘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>ä¸çŸ¥é“æ˜¯è²·ä¸èµ·å¤¾å­é‚„æ˜¯æ€æ¨£ç›´æ¥ç”¨æ‰‹æŠ“è‚‰é›–ç„¶æœ‰å¸¶æ‰‹å¥—ä½†ä¸çŸ¥é“æœ‰æ²’æœ‰å»åšå…¶ä»–äº‹æƒ…è§€æ„ŸçœŸçš„å¾ˆå·®æœ‰å¤ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5184</th>\n",
       "      <td>ã€Œè¦ä»é£¯+ç…é´¨è›‹ã€\\nè¦ä»ğŸ¤æœ‰å¤§ç«ç‚’éç‰¹æœ‰çš„é¦™å‘³ï¼\\né£¯çš„éƒ¨åˆ†åæ¿•ï¼Œè‹¥èƒ½æœ‰è¦å‘³æœƒæ›´å¥½\\nç…é´¨...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>ç”¨é¤äººæ½®ä¸å°‘ï¼Œæœå‹™æ…‹åº¦ç•¥å·®ï¼Œä¸éé›è‚‰é£¯å‘³é“ç®—ä¸éŒ¯ï¼Œæ»·å¤§è…¸ä¹Ÿå¤ å‘³ã€‚åƒè¬ä¸èƒ½å¸¶å¤–é£Ÿï¼Œæœƒè¢«é é‚€ã€‚</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8018</th>\n",
       "      <td>é€±å…­æ™šä¸Šä¹é»äººä¸å¤šï¼Œæ•´é«”ç’°å¢ƒèˆ’é©ã€‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>Cpä¸é«˜ï¼Œä½†å“¡å·¥æœå‹™ä¸éŒ¯ï¼Œå¤–å¸¶é£Ÿç‰©é‚„æœƒæä¾›ç¢—ï¼Œä¸æœƒä¸çµ¦é£Ÿç”¨ã€‚</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>èº«ç‚ºç¾é£Ÿè§€å…‰å®¢è¦ºå¾—æ™®é€š\\næ±è¥¿ä¸å¤§ï¼Œæ‰€ä»¥é€™æ¨£ç®—è²´\\næœå‹™ä¹Ÿå…‡å…‡çš„XD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1442 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  stars\n",
       "6726               æ˜¯è€åº—ã€‚å®ƒçš„æ²¾é†¬ æ˜¯ç”¨è¦æ®¼ã€é ­ç†¬ç…®çš„ æ‰€ä»¥éå¸¸å¥½åƒã€‚é‚„æœ‰è³£å››ç¥æ¹¯&èŠ‹ç¨ã€‚      1\n",
       "8466             ç©ºé–“æ˜äº®ä¹¾æ·¨ï¼Œæœå‹™äººå“¡æ…‹åº¦è¦ªåˆ‡ã€‚äºŒæ¨“åº§ä½å€çš„é•·æ¡Œè¨­æœ‰æ’åº§ï¼Œä½¿ç”¨ä¸‰Cå……é›»æ–¹ä¾¿ã€‚      1\n",
       "1322                         é¤é»å¥½åƒï¼Œæœå‹™å¥½ï¼\\næ¨è–¦è¥¿ç­ç‰™æ²¹è¦ï¼Œé»äº†ä¸æœƒå¾Œæ‚”ã€‚      1\n",
       "256                  ç”¨å¿ƒçš„åº—å®¶ï¼Œé¤é»ä¹Ÿå¥½åƒğŸ˜‹\\nå•¤é…’çœŸçš„å¥½å–é‚„æœ‰ä¼Šæ¯”åˆ©è±¬è‚‰è·Ÿè›‹ç³•æ£’æ£’çš„ğŸ‘      1\n",
       "3235  ä¸çŸ¥é“æ˜¯è²·ä¸èµ·å¤¾å­é‚„æ˜¯æ€æ¨£ç›´æ¥ç”¨æ‰‹æŠ“è‚‰é›–ç„¶æœ‰å¸¶æ‰‹å¥—ä½†ä¸çŸ¥é“æœ‰æ²’æœ‰å»åšå…¶ä»–äº‹æƒ…è§€æ„ŸçœŸçš„å¾ˆå·®æœ‰å¤ ...      0\n",
       "...                                                 ...    ...\n",
       "5184  ã€Œè¦ä»é£¯+ç…é´¨è›‹ã€\\nè¦ä»ğŸ¤æœ‰å¤§ç«ç‚’éç‰¹æœ‰çš„é¦™å‘³ï¼\\né£¯çš„éƒ¨åˆ†åæ¿•ï¼Œè‹¥èƒ½æœ‰è¦å‘³æœƒæ›´å¥½\\nç…é´¨...      1\n",
       "2544      ç”¨é¤äººæ½®ä¸å°‘ï¼Œæœå‹™æ…‹åº¦ç•¥å·®ï¼Œä¸éé›è‚‰é£¯å‘³é“ç®—ä¸éŒ¯ï¼Œæ»·å¤§è…¸ä¹Ÿå¤ å‘³ã€‚åƒè¬ä¸èƒ½å¸¶å¤–é£Ÿï¼Œæœƒè¢«é é‚€ã€‚      0\n",
       "8018                                  é€±å…­æ™šä¸Šä¹é»äººä¸å¤šï¼Œæ•´é«”ç’°å¢ƒèˆ’é©ã€‚      1\n",
       "5179                     Cpä¸é«˜ï¼Œä½†å“¡å·¥æœå‹™ä¸éŒ¯ï¼Œå¤–å¸¶é£Ÿç‰©é‚„æœƒæä¾›ç¢—ï¼Œä¸æœƒä¸çµ¦é£Ÿç”¨ã€‚      0\n",
       "7378                 èº«ç‚ºç¾é£Ÿè§€å…‰å®¢è¦ºå¾—æ™®é€š\\næ±è¥¿ä¸å¤§ï¼Œæ‰€ä»¥é€™æ¨£ç®—è²´\\næœå‹™ä¹Ÿå…‡å…‡çš„XD      0\n",
       "\n",
       "[1442 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "test\n",
    "# idempotence, å°‡è™•ç†çµæœå¦å­˜æˆ tsv ä¾› PyTorch ä½¿ç”¨\n",
    "test.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\n",
    "# df3.category.value_counts() / len(df3)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.592021\n",
       "0    0.407979\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.stars.value_counts() / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.605409\n",
       "0    0.394591\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.stars.value_counts() / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.iloc[0, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å¯¦ä½œä¸€å€‹å¯ä»¥ç”¨ä¾†è®€å–è¨“ç·´ / æ¸¬è©¦é›†çš„ Datasetï¼Œé€™æ˜¯ä½ éœ€è¦å¾¹åº•äº†è§£çš„éƒ¨åˆ†ã€‚\n",
    "æ­¤ Dataset æ¯æ¬¡å°‡ tsv è£¡çš„ä¸€ç­†æˆå°å¥å­è½‰æ›æˆ BERT ç›¸å®¹çš„æ ¼å¼ï¼Œä¸¦å›å‚³ 3 å€‹ tensorsï¼š\n",
    "- tokens_tensorï¼šå…©å€‹å¥å­åˆä½µå¾Œçš„ç´¢å¼•åºåˆ—ï¼ŒåŒ…å« [CLS] èˆ‡ [SEP]\n",
    "- segments_tensorï¼šå¯ä»¥ç”¨ä¾†è­˜åˆ¥å…©å€‹å¥å­ç•Œé™çš„ binary tensor\n",
    "- label_tensorï¼šå°‡åˆ†é¡æ¨™ç±¤è½‰æ›æˆé¡åˆ¥ç´¢å¼•çš„ tensor, å¦‚æœæ˜¯æ¸¬è©¦é›†å‰‡å›å‚³ None\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "    \n",
    "class FakeNewsDataset(Dataset):\n",
    "    # è®€å–å‰è™•ç†å¾Œçš„ tsv æª”ä¸¦åˆå§‹åŒ–ä¸€äº›åƒæ•¸\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"test\"]  # ä¸€èˆ¬è¨“ç·´ä½ æœƒéœ€è¦ dev set\n",
    "        self.mode = mode\n",
    "        # å¤§æ•¸æ“šä½ æœƒéœ€è¦ç”¨ iterator=True\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.label_map = { 0:0, 1:1}\n",
    "        self.tokenizer = tokenizer  # æˆ‘å€‘å°‡ä½¿ç”¨ BERT tokenizer\n",
    "    \n",
    "    # å®šç¾©å›å‚³ä¸€ç­†è¨“ç·´ / æ¸¬è©¦æ•¸æ“šçš„å‡½å¼\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            comment, stars = self.df.iloc[idx, :].values\n",
    "            # label_tensor = None\n",
    "            label_id = self.label_map[stars]\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "        else:\n",
    "            comment, stars = self.df.iloc[idx, :].values\n",
    "            # å°‡ label æ–‡å­—ä¹Ÿè½‰æ›æˆç´¢å¼•æ–¹ä¾¿è½‰æ›æˆ tensor\n",
    "            label_id = self.label_map[stars]\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "            \n",
    "        # å»ºç«‹ç¬¬ä¸€å€‹å¥å­çš„ BERT tokens ä¸¦åŠ å…¥åˆ†éš”ç¬¦è™Ÿ [SEP]\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_a = self.tokenizer.tokenize(comment)\n",
    "        word_pieces += tokens_a + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "\n",
    "        \n",
    "        # å°‡æ•´å€‹ token åºåˆ—è½‰æ›æˆç´¢å¼•åºåˆ—\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # å°‡ç¬¬ä¸€å¥åŒ…å« [SEP] çš„ token ä½ç½®è¨­ç‚º 0ï¼Œå…¶ä»–ç‚º 1 è¡¨ç¤ºç¬¬äºŒå¥\n",
    "        segments_tensor = torch.tensor([0] * len_a , dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "# åˆå§‹åŒ–ä¸€å€‹å°ˆé–€è®€å–è¨“ç·´æ¨£æœ¬çš„ Datasetï¼Œä½¿ç”¨ä¸­æ–‡ BERT æ–·è©\n",
    "trainset = FakeNewsDataset(\"train\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åŸå§‹æ–‡æœ¬]\n",
      "å¥å­ 1ï¼šç¬¬ä¸€æ¬¡ä¾†é€™å®¶åº—ç”¨é¤ã€ç’°å¢ƒä¹¾æ·¨ã€ç”¨é¤æ°›åœå¾ˆæ”¾é¬†ï¼é¤é»æ–¹é¢ä¹Ÿå¾ˆå¥½åƒï¼\n",
      "\n",
      "åˆ†é¡  ï¼š1\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset å›å‚³çš„ tensors]\n",
      "tokens_tensor  ï¼štensor([ 101, 5018,  671, 3613,  889, 6857, 2157, 2421, 4500, 7623,  510, 4472,\n",
      "        1862,  746, 3912,  510, 4500, 7623, 3702, 1752, 2523, 3123, 7777, 8013,\n",
      "        7623, 7953, 3175, 7481,  738, 2523, 1962, 1391, 8013,  102])\n",
      "\n",
      "segments_tensorï¼štensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "label_tensor   ï¼š1\n",
      "\n",
      "--------------------\n",
      "\n",
      "[é‚„åŸ tokens_tensors]\n",
      "[CLS]ç¬¬ä¸€æ¬¡ä¾†é€™å®¶åº—ç”¨é¤ã€ç’°å¢ƒä¹¾æ·¨ã€ç”¨é¤æ°›åœå¾ˆæ”¾é¬†ï¼é¤é»æ–¹é¢ä¹Ÿå¾ˆå¥½åƒï¼[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 300\n",
    "\n",
    "# å°‡åŸå§‹æ–‡æœ¬æ‹¿å‡ºåšæ¯”è¼ƒ\n",
    "comment, stars = trainset.df.iloc[sample_idx].values\n",
    "\n",
    "# åˆ©ç”¨å‰›å‰›å»ºç«‹çš„ Dataset å–å‡ºè½‰æ›å¾Œçš„ id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
    "\n",
    "# å°‡ tokens_tensor é‚„åŸæˆæ–‡æœ¬\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \"\".join(tokens)\n",
    "\n",
    "print(f\"\"\"[åŸå§‹æ–‡æœ¬]\n",
    "å¥å­ 1ï¼š{comment}\n",
    "\n",
    "åˆ†é¡  ï¼š{stars}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset å›å‚³çš„ tensors]\n",
    "tokens_tensor  ï¼š{tokens_tensor}\n",
    "\n",
    "segments_tensorï¼š{segments_tensor}\n",
    "\n",
    "label_tensor   ï¼š{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[é‚„åŸ tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å¯¦ä½œå¯ä»¥ä¸€æ¬¡å›å‚³ä¸€å€‹ mini-batch çš„ DataLoader\n",
    "é€™å€‹ DataLoader åƒæˆ‘å€‘ä¸Šé¢å®šç¾©çš„ `FakeNewsDataset`ï¼Œ\n",
    "å›å‚³è¨“ç·´ BERT æ™‚æœƒéœ€è¦çš„ 4 å€‹ tensorsï¼š\n",
    "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
    "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
    "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
    "- label_ids       : (batch_size)\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# é€™å€‹å‡½å¼çš„è¼¸å…¥ `samples` æ˜¯ä¸€å€‹ listï¼Œè£¡é ­çš„æ¯å€‹ element éƒ½æ˜¯\n",
    "# å‰›å‰›å®šç¾©çš„ `FakeNewsDataset` å›å‚³çš„ä¸€å€‹æ¨£æœ¬ï¼Œæ¯å€‹æ¨£æœ¬éƒ½åŒ…å« 3 tensorsï¼š\n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "# å®ƒæœƒå°å‰å…©å€‹ tensors ä½œ zero paddingï¼Œä¸¦ç”¢ç”Ÿå‰é¢èªªæ˜éçš„ masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # æ¸¬è©¦é›†æœ‰ labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pad åˆ°åŒä¸€åºåˆ—é•·åº¦\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masksï¼Œå°‡ tokens_tensors è£¡é ­ä¸ç‚º zero padding\n",
    "    # çš„ä½ç½®è¨­ç‚º 1 è®“ BERT åªé—œæ³¨é€™äº›ä½ç½®çš„ tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€å€‹æ¯æ¬¡å›å‚³ 64 å€‹è¨“ç·´æ¨£æœ¬çš„ DataLoader\n",
    "# åˆ©ç”¨ `collate_fn` å°‡ list of samples åˆä½µæˆä¸€å€‹ mini-batch æ˜¯é—œéµ\n",
    "BATCH_SIZE = 4\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥ä¸€å€‹å¯ä»¥åšä¸­æ–‡å¤šåˆ†é¡ä»»å‹™çš„æ¨¡å‹ï¼Œn_class = 2\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "NUM_LABELS = 2\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# high-level é¡¯ç¤ºæ­¤æ¨¡å‹è£¡çš„ modules\n",
    "# print(\"\"\"\n",
    "# name            module\n",
    "# ----------------------\"\"\")\n",
    "# for name, module in model.named_children():\n",
    "#     if name == \"bert\":\n",
    "#         for n, _ in module.named_children():\n",
    "#             print(f\"{name}:{n}\")\n",
    "#     else:\n",
    "#         print(\"{:15} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "classification acc: 0.987510841283608\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "å®šç¾©ä¸€å€‹å¯ä»¥é‡å°ç‰¹å®š DataLoader å–å¾—æ¨¡å‹é æ¸¬çµæœä»¥åŠåˆ†é¡æº–ç¢ºåº¦çš„å‡½å¼\n",
    "ä¹‹å¾Œä¹Ÿå¯ä»¥ç”¨ä¾†ç”Ÿæˆä¸Šå‚³åˆ° Kaggle ç«¶è³½çš„é æ¸¬çµæœ\n",
    "\n",
    "2019/11/22 æ›´æ–°ï¼šåœ¨å°‡ `tokens`ã€`segments_tensors` ç­‰ tensors\n",
    "ä¸Ÿå…¥æ¨¡å‹æ™‚ï¼Œå¼·åŠ›å»ºè­°æŒ‡å®šæ¯å€‹ tensor å°æ‡‰çš„åƒæ•¸åç¨±ï¼Œä»¥é¿å… HuggingFace\n",
    "æ›´æ–° repo ç¨‹å¼ç¢¼ä¸¦æ”¹è®Šåƒæ•¸é †åºæ™‚å½±éŸ¿åˆ°æˆ‘å€‘çš„çµæœã€‚\n",
    "\"\"\"\n",
    "\n",
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # éå·¡æ•´å€‹è³‡æ–™é›†\n",
    "        for data in dataloader:\n",
    "            # å°‡æ‰€æœ‰ tensors ç§»åˆ° GPU ä¸Š\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # åˆ¥å¿˜è¨˜å‰ 3 å€‹ tensors åˆ†åˆ¥ç‚º tokens, segments ä»¥åŠ masks\n",
    "            # ä¸”å¼·çƒˆå»ºè­°åœ¨å°‡é€™äº› tensors ä¸Ÿå…¥ `model` æ™‚æŒ‡å®šå°æ‡‰çš„åƒæ•¸åç¨±\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # ç”¨ä¾†è¨ˆç®—è¨“ç·´é›†çš„åˆ†é¡æº–ç¢ºç‡\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # å°‡ç•¶å‰ batch è¨˜éŒ„ä¸‹ä¾†\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "    \n",
    "# è®“æ¨¡å‹è·‘åœ¨ GPU ä¸Šä¸¦å–å¾—è¨“ç·´é›†çš„åˆ†é¡æº–ç¢ºç‡\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "print(\"classification acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æ•´å€‹åˆ†é¡æ¨¡å‹çš„åƒæ•¸é‡ï¼š102269186\n",
      "ç·šæ€§åˆ†é¡å™¨çš„åƒæ•¸é‡ï¼š1538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_learnable_params(module):\n",
    "    return [p for p in module.parameters() if p.requires_grad]\n",
    "     \n",
    "model_params = get_learnable_params(model)\n",
    "clf_params = get_learnable_params(model.classifier)\n",
    "\n",
    "print(f\"\"\"\n",
    "æ•´å€‹åˆ†é¡æ¨¡å‹çš„åƒæ•¸é‡ï¼š{sum(p.numel() for p in model_params)}\n",
    "ç·šæ€§åˆ†é¡å™¨çš„åƒæ•¸é‡ï¼š{sum(p.numel() for p in clf_params)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 234.965, acc: 0.992\n",
      "[epoch 2] loss: 37.692, acc: 0.989\n",
      "CPU times: total: 8min 44s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# è¨“ç·´æ¨¡å¼\n",
    "model.train()\n",
    "\n",
    "# ä½¿ç”¨ Adam Optim æ›´æ–°æ•´å€‹åˆ†é¡æ¨¡å‹çš„åƒæ•¸\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "EPOCHS = 2  # å¹¸é‹æ•¸å­—\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        # å°‡åƒæ•¸æ¢¯åº¦æ­¸é›¶\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # ç´€éŒ„ç•¶å‰ batch loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # è¨ˆç®—åˆ†é¡æº–ç¢ºç‡\n",
    "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[åŸå§‹æ–‡æœ¬]\n",
      "å¥å­ 1ï¼šé€™è¶Ÿå°å—éŠç„¡æ„è¦‹çœ‹åˆ°çš„è‚‰åœ“\n",
      "æŠ±è‘—åƒåƒçœ‹çš„æƒ³æ³•\n",
      "çš®çš„å£æ„Ÿéæ–¼è»Ÿçˆ›\n",
      "å››ç¥æ¹¯æœ‰é»æ·¡æ·¡çš„å‘³é“\n",
      "è€é—†æ€§æ ¼ç›´çˆ½çš„å€‹æ€§\n",
      "è®“æˆ‘å€‘å°çœ¼ä¸€ç¬‘\n",
      "è¶•ç·Šåƒå®Œé»˜é»˜é£„èµ°\n",
      "é‡é»æˆ‘å€‘æœ‰ä»˜éŒ¢å•¦\n",
      "\n",
      "åˆ†é¡  ï¼š0\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset å›å‚³çš„ tensors]\n",
      "tokens_tensor  ï¼štensor([ 101, 6857, 6636, 1378, 1298, 6879, 4192, 2692, 6210, 4692, 1168, 4638,\n",
      "        5489, 1755, 2849, 5865, 1391, 1391, 4692, 4638, 2682, 3791, 4649, 4638,\n",
      "        1366, 2697, 6882, 3176, 6727, 4258, 1724, 4868, 3966, 3300, 7953, 3909,\n",
      "        3909, 4638, 1456, 6887, 5439, 7293, 2595, 3419, 4684, 4272, 4638,  943,\n",
      "        2595, 6366, 2769,  947, 2205, 4706,  671, 5010, 6634, 5215, 1391, 2130,\n",
      "        7949, 7949, 7597, 6624, 7028, 7953, 2769,  947, 3300,  802, 7092, 1568,\n",
      "         102])\n",
      "\n",
      "segments_tensorï¼štensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "\n",
      "label_tensor   ï¼š0\n",
      "\n",
      "--------------------\n",
      "\n",
      "[é‚„åŸ tokens_tensors]\n",
      "[CLS]é€™è¶Ÿå°å—éŠç„¡æ„è¦‹çœ‹åˆ°çš„è‚‰åœ“æŠ±è‘—åƒåƒçœ‹çš„æƒ³æ³•çš®çš„å£æ„Ÿéæ–¼è»Ÿçˆ›å››ç¥æ¹¯æœ‰é»æ·¡æ·¡çš„å‘³é“è€é—†æ€§æ ¼ç›´çˆ½çš„å€‹æ€§è®“æˆ‘å€‘å°çœ¼ä¸€ç¬‘è¶•ç·Šåƒå®Œé»˜é»˜é£„èµ°é‡é»æˆ‘å€‘æœ‰ä»˜éŒ¢å•¦[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 20\n",
    "testset = FakeNewsDataset(\"test\", tokenizer=tokenizer)\n",
    "\n",
    "# å°‡åŸå§‹æ–‡æœ¬æ‹¿å‡ºåšæ¯”è¼ƒ\n",
    "comment, stars = testset.df.iloc[sample_idx].values\n",
    "\n",
    "# åˆ©ç”¨å‰›å‰›å»ºç«‹çš„ Dataset å–å‡ºè½‰æ›å¾Œçš„ id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = testset[sample_idx]\n",
    "\n",
    "# å°‡ tokens_tensor é‚„åŸæˆæ–‡æœ¬\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \"\".join(tokens)\n",
    "\n",
    "print(f\"\"\"[åŸå§‹æ–‡æœ¬]\n",
    "å¥å­ 1ï¼š{comment}\n",
    "\n",
    "åˆ†é¡  ï¼š{stars}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset å›å‚³çš„ tensors]\n",
    "tokens_tensor  ï¼š{tokens_tensor}\n",
    "\n",
    "segments_tensorï¼š{segments_tensor}\n",
    "\n",
    "label_tensor   ï¼š{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[é‚„åŸ tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986130374479889\n",
      "CPU times: total: 14.6 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å»ºç«‹æ¸¬è©¦é›†ã€‚é€™é‚Šæˆ‘å€‘å¯ä»¥ç”¨è·Ÿè¨“ç·´æ™‚ä¸åŒçš„ batch_sizeï¼Œçœ‹ä½  GPU å¤šå¤§\n",
    "testset = FakeNewsDataset(\"test\", tokenizer=tokenizer)\n",
    "testloader = DataLoader(testset, batch_size=4, \n",
    "                        collate_fn=create_mini_batch)\n",
    "\n",
    "# ç”¨åˆ†é¡æ¨¡å‹é æ¸¬æ¸¬è©¦é›†\n",
    "t, predictions = get_predictions(model, testloader, compute_acc=True)\n",
    "print(predictions)\n",
    "\n",
    "# ç”¨ä¾†å°‡é æ¸¬çš„ label id è½‰å› label æ–‡å­—\n",
    "#index_map = {v: k for k, v in testset.label_map.items()}\n",
    "\n",
    "# ç”Ÿæˆ Kaggle ç¹³äº¤æª”æ¡ˆ\n",
    "# df = pd.DataFrame({\"Category\": predictions.tolist()})\n",
    "# df['Category'] = df.Category.apply(lambda x: index_map[x])\n",
    "# df_pred = pd.concat([testset.df.loc[:, [\"Id\"]], \n",
    "#                           df.loc[:, 'Category']], axis=1)\n",
    "#df_pred.to_csv('bert_1_prec_training_samples.csv', index=False)\n",
    "#df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'emo1017.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    3429 MB |    3429 MB |    2184 GB |    2181 GB |\\n|       from large pool |    3428 MB |    3428 MB |    2183 GB |    2180 GB |\\n|       from small pool |       1 MB |       1 MB |       0 GB |       0 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    3429 MB |    3429 MB |    2184 GB |    2181 GB |\\n|       from large pool |    3428 MB |    3428 MB |    2183 GB |    2180 GB |\\n|       from small pool |       1 MB |       1 MB |       0 GB |       0 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    3532 MB |    3532 MB |    3580 MB |   49152 KB |\\n|       from large pool |    3530 MB |    3530 MB |    3578 MB |   49152 KB |\\n|       from small pool |       2 MB |       2 MB |       2 MB |       0 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  104599 KB |  546378 KB |     912 GB |     912 GB |\\n|       from large pool |  104169 KB |  545184 KB |     912 GB |     912 GB |\\n|       from small pool |     430 KB |    2042 KB |       0 GB |       0 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     395    |     395    |   73863    |   73468    |\\n|       from large pool |     187    |     187    |   57836    |   57649    |\\n|       from small pool |     208    |     208    |   16027    |   15819    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     395    |     395    |   73863    |   73468    |\\n|       from large pool |     187    |     187    |   57836    |   57649    |\\n|       from small pool |     208    |     208    |   16027    |   15819    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      69    |      69    |      71    |       2    |\\n|       from large pool |      68    |      68    |      70    |       2    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      54    |      63    |   60665    |   60611    |\\n|       from large pool |      52    |      61    |   54375    |   54323    |\\n|       from small pool |       2    |       7    |    6290    |    6288    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d07ada2db3a750ea7525ef0abae1dd8d2e024d709104a053d6ba9a14985ab36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
