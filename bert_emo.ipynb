{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本： 1.12.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定繁簡中文 BERT-BASE 預訓練模型\n",
    "\n",
    "# 取得此預訓練模型所使用的 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "print(\"PyTorch 版本：\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650 SUPER'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# torch.cuda.device_count()\n",
    "\n",
    "\n",
    "#torch.cuda.current_device()\n",
    "\n",
    "\n",
    "#torch.cuda.device(0)\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>stars</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>生日聚餐選了這間餐廳，整體環境很乾淨也不會太喧鬧，服務也很周到。主菜點了鹿菲力與鴨胸套餐都很...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>應該五顆星的，可惜沙拉的盤子有缺角，少了一顆星。食材使用高級，服務人員解說清楚。提供包場服務...</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>料理味道不錯\\n海鮮煎餅很好吃！推薦必點\\n自製香腸份量也蠻夠的，值得去吃\\n只是蚊子真的比...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>好市集是我的愛店，不知道要去哪裏吃飯的時候，來這裡就對了。地中海創意料理味道與口感都很不錯，...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>車子要停外面收費處，個人感覺豬排比較好吃肉很嫩，價位有點貴東西都要單點喔</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>便宜cp值很高的享受，二樓挑高視野棒，一樓通常客滿</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>價格合理，氣氛很好，讓人感覺很悠閒。</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>不知為何，跟其他家喝起來味道不一樣…</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>舒適，服務態度還能再加強就更是滿分</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>非常適合去店裡點杯飲料\\n吃個三明治</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7207 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  stars  length\n",
       "4     生日聚餐選了這間餐廳，整體環境很乾淨也不會太喧鬧，服務也很周到。主菜點了鹿菲力與鴨胸套餐都很...      1      53\n",
       "5     應該五顆星的，可惜沙拉的盤子有缺角，少了一顆星。食材使用高級，服務人員解說清楚。提供包場服務...      1      51\n",
       "6     料理味道不錯\\n海鮮煎餅很好吃！推薦必點\\n自製香腸份量也蠻夠的，值得去吃\\n只是蚊子真的比...      1      52\n",
       "7     好市集是我的愛店，不知道要去哪裏吃飯的時候，來這裡就對了。地中海創意料理味道與口感都很不錯，...      1      60\n",
       "8                  車子要停外面收費處，個人感覺豬排比較好吃肉很嫩，價位有點貴東西都要單點喔      1      36\n",
       "...                                                 ...    ...     ...\n",
       "9595                          便宜cp值很高的享受，二樓挑高視野棒，一樓通常客滿      1      25\n",
       "9596                                 價格合理，氣氛很好，讓人感覺很悠閒。      1      18\n",
       "9597                                 不知為何，跟其他家喝起來味道不一樣…      0      18\n",
       "9598                                  舒適，服務態度還能再加強就更是滿分      1      17\n",
       "9599                                 非常適合去店裡點杯飲料\\n吃個三明治      1      17\n",
       "\n",
       "[7207 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"評論分數.csv\")\n",
    "\n",
    "df = df.dropna()\n",
    "df['length'] = df.comment.str.len()\n",
    "df = df[df.length < 60]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>非常棒的用餐體驗，服務人員親切用心，午餐時間沒有羊排，也特地幫我們詢問廚房幫忙準備😋😋😋</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>這是一間有別以往\\n其他路易莎的旗艦店\\n保證每個客人買完咖啡都會如沐春風\\n都會期許自己像...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>嘉義知名老店,我小時候偶爾來吃,Frank倒是慕名而來.火雞肉飯還好,滷筍絲好吃,金針排骨湯...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>不難吃但沒有到一定要來吃，男老闆感覺好像不是很想跟客人說話</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>很讚的經典法國餐，細緻的品味，下次一定要來。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>小時候吃到大的味道！不管其他人說還有更好吃的雞肉飯，但這個味道最地道。只是一甲子的店有些歲月...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>我在嘉義雞肉飯找到喜好之 噴水真的不行，整個便當我只對蛋有印象，冷掉味道好膩啊啊啊～</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371</th>\n",
       "      <td>蝦仁不紮實感帶沙腸有蝦味\\n米飯偏軟爛接近沒湯的蝦泡飯</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>服務很好，餐點都是單點式，一人平均花費$800~$900，吃不到什麼東西，很空虛</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9249</th>\n",
       "      <td>這間路易莎的飲料相較於餐點好吃</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  stars\n",
       "948        非常棒的用餐體驗，服務人員親切用心，午餐時間沒有羊排，也特地幫我們詢問廚房幫忙準備😋😋😋      1\n",
       "9492  這是一間有別以往\\n其他路易莎的旗艦店\\n保證每個客人買完咖啡都會如沐春風\\n都會期許自己像...      1\n",
       "2019  嘉義知名老店,我小時候偶爾來吃,Frank倒是慕名而來.火雞肉飯還好,滷筍絲好吃,金針排骨湯...      0\n",
       "6622                      不難吃但沒有到一定要來吃，男老闆感覺好像不是很想跟客人說話      0\n",
       "952                              很讚的經典法國餐，細緻的品味，下次一定要來。      1\n",
       "...                                                 ...    ...\n",
       "3126  小時候吃到大的味道！不管其他人說還有更好吃的雞肉飯，但這個味道最地道。只是一甲子的店有些歲月...      1\n",
       "2765         我在嘉義雞肉飯找到喜好之 噴水真的不行，整個便當我只對蛋有印象，冷掉味道好膩啊啊啊～      0\n",
       "5371                        蝦仁不紮實感帶沙腸有蝦味\\n米飯偏軟爛接近沒湯的蝦泡飯      0\n",
       "874            服務很好，餐點都是單點式，一人平均花費$800~$900，吃不到什麼東西，很空虛      0\n",
       "9249                                    這間路易莎的飲料相較於餐點好吃      1\n",
       "\n",
       "[5765 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['comment']\n",
    "y = df['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=77)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train\n",
    "# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\n",
    "train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "# df3.category.value_counts() / len(df3)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>是老店。它的沾醬 是用蝦殼、頭熬煮的 所以非常好吃。還有賣四神湯&amp;芋稞。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>空間明亮乾淨，服務人員態度親切。二樓座位區的長桌設有插座，使用三C充電方便。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>餐點好吃，服務好！\\n推薦西班牙油蝦，點了不會後悔。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>用心的店家，餐點也好吃😋\\n啤酒真的好喝還有伊比利豬肉跟蛋糕棒棒的👍</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>不知道是買不起夾子還是怎樣直接用手抓肉雖然有帶手套但不知道有沒有去做其他事情觀感真的很差有夠...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5184</th>\n",
       "      <td>「蝦仁飯+煎鴨蛋」\\n蝦仁🍤有大火炒過特有的香味！\\n飯的部分偏濕，若能有蝦味會更好\\n煎鴨...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>用餐人潮不少，服務態度略差，不過雞肉飯味道算不錯，滷大腸也夠味。千萬不能帶外食，會被靠邀。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8018</th>\n",
       "      <td>週六晚上九點人不多，整體環境舒適。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>Cp不高，但員工服務不錯，外帶食物還會提供碗，不會不給食用。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>身為美食觀光客覺得普通\\n東西不大，所以這樣算貴\\n服務也兇兇的XD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  stars\n",
       "6726               是老店。它的沾醬 是用蝦殼、頭熬煮的 所以非常好吃。還有賣四神湯&芋稞。      1\n",
       "8466             空間明亮乾淨，服務人員態度親切。二樓座位區的長桌設有插座，使用三C充電方便。      1\n",
       "1322                         餐點好吃，服務好！\\n推薦西班牙油蝦，點了不會後悔。      1\n",
       "256                  用心的店家，餐點也好吃😋\\n啤酒真的好喝還有伊比利豬肉跟蛋糕棒棒的👍      1\n",
       "3235  不知道是買不起夾子還是怎樣直接用手抓肉雖然有帶手套但不知道有沒有去做其他事情觀感真的很差有夠...      0\n",
       "...                                                 ...    ...\n",
       "5184  「蝦仁飯+煎鴨蛋」\\n蝦仁🍤有大火炒過特有的香味！\\n飯的部分偏濕，若能有蝦味會更好\\n煎鴨...      1\n",
       "2544      用餐人潮不少，服務態度略差，不過雞肉飯味道算不錯，滷大腸也夠味。千萬不能帶外食，會被靠邀。      0\n",
       "8018                                  週六晚上九點人不多，整體環境舒適。      1\n",
       "5179                     Cp不高，但員工服務不錯，外帶食物還會提供碗，不會不給食用。      0\n",
       "7378                 身為美食觀光客覺得普通\\n東西不大，所以這樣算貴\\n服務也兇兇的XD      0\n",
       "\n",
       "[1442 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "test\n",
    "# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\n",
    "test.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\n",
    "# df3.category.value_counts() / len(df3)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.592021\n",
       "0    0.407979\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.stars.value_counts() / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.605409\n",
       "0    0.394591\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.stars.value_counts() / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.iloc[0, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "實作一個可以用來讀取訓練 / 測試集的 Dataset，這是你需要徹底了解的部分。\n",
    "此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n",
    "- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n",
    "- segments_tensor：可以用來識別兩個句子界限的 binary tensor\n",
    "- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "    \n",
    "class FakeNewsDataset(Dataset):\n",
    "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"test\"]  # 一般訓練你會需要 dev set\n",
    "        self.mode = mode\n",
    "        # 大數據你會需要用 iterator=True\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.label_map = { 0:0, 1:1}\n",
    "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
    "    \n",
    "    # 定義回傳一筆訓練 / 測試數據的函式\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            comment, stars = self.df.iloc[idx, :].values\n",
    "            # label_tensor = None\n",
    "            label_id = self.label_map[stars]\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "        else:\n",
    "            comment, stars = self.df.iloc[idx, :].values\n",
    "            # 將 label 文字也轉換成索引方便轉換成 tensor\n",
    "            label_id = self.label_map[stars]\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "            \n",
    "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_a = self.tokenizer.tokenize(comment)\n",
    "        word_pieces += tokens_a + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "\n",
    "        \n",
    "        # 將整個 token 序列轉換成索引序列\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
    "        segments_tensor = torch.tensor([0] * len_a , dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
    "trainset = FakeNewsDataset(\"train\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原始文本]\n",
      "句子 1：第一次來這家店用餐、環境乾淨、用餐氛圍很放鬆！餐點方面也很好吃！\n",
      "\n",
      "分類  ：1\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset 回傳的 tensors]\n",
      "tokens_tensor  ：tensor([ 101, 5018,  671, 3613,  889, 6857, 2157, 2421, 4500, 7623,  510, 4472,\n",
      "        1862,  746, 3912,  510, 4500, 7623, 3702, 1752, 2523, 3123, 7777, 8013,\n",
      "        7623, 7953, 3175, 7481,  738, 2523, 1962, 1391, 8013,  102])\n",
      "\n",
      "segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "label_tensor   ：1\n",
      "\n",
      "--------------------\n",
      "\n",
      "[還原 tokens_tensors]\n",
      "[CLS]第一次來這家店用餐、環境乾淨、用餐氛圍很放鬆！餐點方面也很好吃！[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 300\n",
    "\n",
    "# 將原始文本拿出做比較\n",
    "comment, stars = trainset.df.iloc[sample_idx].values\n",
    "\n",
    "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
    "\n",
    "# 將 tokens_tensor 還原成文本\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \"\".join(tokens)\n",
    "\n",
    "print(f\"\"\"[原始文本]\n",
    "句子 1：{comment}\n",
    "\n",
    "分類  ：{stars}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset 回傳的 tensors]\n",
    "tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "segments_tensor：{segments_tensor}\n",
    "\n",
    "label_tensor   ：{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[還原 tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "實作可以一次回傳一個 mini-batch 的 DataLoader\n",
    "這個 DataLoader 吃我們上面定義的 `FakeNewsDataset`，\n",
    "回傳訓練 BERT 時會需要的 4 個 tensors：\n",
    "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
    "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
    "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
    "- label_ids       : (batch_size)\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n",
    "# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # 測試集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
    "\n",
    "\n",
    "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
    "BATCH_SIZE = 4\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入一個可以做中文多分類任務的模型，n_class = 2\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "NUM_LABELS = 2\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# high-level 顯示此模型裡的 modules\n",
    "# print(\"\"\"\n",
    "# name            module\n",
    "# ----------------------\"\"\")\n",
    "# for name, module in model.named_children():\n",
    "#     if name == \"bert\":\n",
    "#         for n, _ in module.named_children():\n",
    "#             print(f\"{name}:{n}\")\n",
    "#     else:\n",
    "#         print(\"{:15} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "classification acc: 0.987510841283608\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "定義一個可以針對特定 DataLoader 取得模型預測結果以及分類準確度的函式\n",
    "之後也可以用來生成上傳到 Kaggle 競賽的預測結果\n",
    "\n",
    "2019/11/22 更新：在將 `tokens`、`segments_tensors` 等 tensors\n",
    "丟入模型時，強力建議指定每個 tensor 對應的參數名稱，以避免 HuggingFace\n",
    "更新 repo 程式碼並改變參數順序時影響到我們的結果。\n",
    "\"\"\"\n",
    "\n",
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "    \n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "print(\"classification acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "整個分類模型的參數量：102269186\n",
      "線性分類器的參數量：1538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_learnable_params(module):\n",
    "    return [p for p in module.parameters() if p.requires_grad]\n",
    "     \n",
    "model_params = get_learnable_params(model)\n",
    "clf_params = get_learnable_params(model.classifier)\n",
    "\n",
    "print(f\"\"\"\n",
    "整個分類模型的參數量：{sum(p.numel() for p in model_params)}\n",
    "線性分類器的參數量：{sum(p.numel() for p in clf_params)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 234.965, acc: 0.992\n",
      "[epoch 2] loss: 37.692, acc: 0.989\n",
      "CPU times: total: 8min 44s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 訓練模式\n",
    "model.train()\n",
    "\n",
    "# 使用 Adam Optim 更新整個分類模型的參數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "EPOCHS = 2  # 幸運數字\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # 計算分類準確率\n",
    "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原始文本]\n",
      "句子 1：這趟台南遊無意見看到的肉圓\n",
      "抱著吃吃看的想法\n",
      "皮的口感過於軟爛\n",
      "四神湯有點淡淡的味道\n",
      "老闆性格直爽的個性\n",
      "讓我們對眼一笑\n",
      "趕緊吃完默默飄走\n",
      "重點我們有付錢啦\n",
      "\n",
      "分類  ：0\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset 回傳的 tensors]\n",
      "tokens_tensor  ：tensor([ 101, 6857, 6636, 1378, 1298, 6879, 4192, 2692, 6210, 4692, 1168, 4638,\n",
      "        5489, 1755, 2849, 5865, 1391, 1391, 4692, 4638, 2682, 3791, 4649, 4638,\n",
      "        1366, 2697, 6882, 3176, 6727, 4258, 1724, 4868, 3966, 3300, 7953, 3909,\n",
      "        3909, 4638, 1456, 6887, 5439, 7293, 2595, 3419, 4684, 4272, 4638,  943,\n",
      "        2595, 6366, 2769,  947, 2205, 4706,  671, 5010, 6634, 5215, 1391, 2130,\n",
      "        7949, 7949, 7597, 6624, 7028, 7953, 2769,  947, 3300,  802, 7092, 1568,\n",
      "         102])\n",
      "\n",
      "segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "\n",
      "label_tensor   ：0\n",
      "\n",
      "--------------------\n",
      "\n",
      "[還原 tokens_tensors]\n",
      "[CLS]這趟台南遊無意見看到的肉圓抱著吃吃看的想法皮的口感過於軟爛四神湯有點淡淡的味道老闆性格直爽的個性讓我們對眼一笑趕緊吃完默默飄走重點我們有付錢啦[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 20\n",
    "testset = FakeNewsDataset(\"test\", tokenizer=tokenizer)\n",
    "\n",
    "# 將原始文本拿出做比較\n",
    "comment, stars = testset.df.iloc[sample_idx].values\n",
    "\n",
    "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = testset[sample_idx]\n",
    "\n",
    "# 將 tokens_tensor 還原成文本\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \"\".join(tokens)\n",
    "\n",
    "print(f\"\"\"[原始文本]\n",
    "句子 1：{comment}\n",
    "\n",
    "分類  ：{stars}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset 回傳的 tensors]\n",
    "tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "segments_tensor：{segments_tensor}\n",
    "\n",
    "label_tensor   ：{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[還原 tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986130374479889\n",
      "CPU times: total: 14.6 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 建立測試集。這邊我們可以用跟訓練時不同的 batch_size，看你 GPU 多大\n",
    "testset = FakeNewsDataset(\"test\", tokenizer=tokenizer)\n",
    "testloader = DataLoader(testset, batch_size=4, \n",
    "                        collate_fn=create_mini_batch)\n",
    "\n",
    "# 用分類模型預測測試集\n",
    "t, predictions = get_predictions(model, testloader, compute_acc=True)\n",
    "print(predictions)\n",
    "\n",
    "# 用來將預測的 label id 轉回 label 文字\n",
    "#index_map = {v: k for k, v in testset.label_map.items()}\n",
    "\n",
    "# 生成 Kaggle 繳交檔案\n",
    "# df = pd.DataFrame({\"Category\": predictions.tolist()})\n",
    "# df['Category'] = df.Category.apply(lambda x: index_map[x])\n",
    "# df_pred = pd.concat([testset.df.loc[:, [\"Id\"]], \n",
    "#                           df.loc[:, 'Category']], axis=1)\n",
    "#df_pred.to_csv('bert_1_prec_training_samples.csv', index=False)\n",
    "#df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'emo1017.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    3429 MB |    3429 MB |    2184 GB |    2181 GB |\\n|       from large pool |    3428 MB |    3428 MB |    2183 GB |    2180 GB |\\n|       from small pool |       1 MB |       1 MB |       0 GB |       0 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    3429 MB |    3429 MB |    2184 GB |    2181 GB |\\n|       from large pool |    3428 MB |    3428 MB |    2183 GB |    2180 GB |\\n|       from small pool |       1 MB |       1 MB |       0 GB |       0 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    3532 MB |    3532 MB |    3580 MB |   49152 KB |\\n|       from large pool |    3530 MB |    3530 MB |    3578 MB |   49152 KB |\\n|       from small pool |       2 MB |       2 MB |       2 MB |       0 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  104599 KB |  546378 KB |     912 GB |     912 GB |\\n|       from large pool |  104169 KB |  545184 KB |     912 GB |     912 GB |\\n|       from small pool |     430 KB |    2042 KB |       0 GB |       0 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     395    |     395    |   73863    |   73468    |\\n|       from large pool |     187    |     187    |   57836    |   57649    |\\n|       from small pool |     208    |     208    |   16027    |   15819    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     395    |     395    |   73863    |   73468    |\\n|       from large pool |     187    |     187    |   57836    |   57649    |\\n|       from small pool |     208    |     208    |   16027    |   15819    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      69    |      69    |      71    |       2    |\\n|       from large pool |      68    |      68    |      70    |       2    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      54    |      63    |   60665    |   60611    |\\n|       from large pool |      52    |      61    |   54375    |   54323    |\\n|       from small pool |       2    |       7    |    6290    |    6288    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d07ada2db3a750ea7525ef0abae1dd8d2e024d709104a053d6ba9a14985ab36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
